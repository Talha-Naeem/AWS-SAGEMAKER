{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "constitutional-eagle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://amazon-reviews-pds/tsv/amazon_reviews_us_Camera_v1_00.tsv.gz to ../../../tmp/amazon_reviews_us_Camera_v1_00.tsv.gz\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "# this is new and  not shown in the book (--no-sign-request)\n",
    "aws s3 cp --no-sign-request s3://amazon-reviews-pds/tsv/amazon_reviews_us_Camera_v1_00.tsv.gz /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "starting-injection",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fifth-nepal",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 85458: expected 15 fields, saw 22\\nSkipping line 91161: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 166123: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 225458: expected 15 fields, saw 22\\nSkipping line 229936: expected 15 fields, saw 22\\nSkipping line 259297: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 284728: expected 15 fields, saw 22\\nSkipping line 286334: expected 15 fields, saw 22\\nSkipping line 293400: expected 15 fields, saw 22\\nSkipping line 294415: expected 15 fields, saw 22\\nSkipping line 308150: expected 15 fields, saw 22\\nSkipping line 315022: expected 15 fields, saw 22\\nSkipping line 315730: expected 15 fields, saw 22\\nSkipping line 316071: expected 15 fields, saw 22\\nSkipping line 326729: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 329101: expected 15 fields, saw 22\\nSkipping line 333077: expected 15 fields, saw 22\\nSkipping line 377031: expected 15 fields, saw 22\\nSkipping line 389496: expected 15 fields, saw 22\\nSkipping line 390486: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 418308: expected 15 fields, saw 22\\nSkipping line 454332: expected 15 fields, saw 22\\nSkipping line 458342: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 460704: expected 15 fields, saw 22\\nSkipping line 466250: expected 15 fields, saw 22\\nSkipping line 486023: expected 15 fields, saw 22\\nSkipping line 492819: expected 15 fields, saw 22\\nSkipping line 517468: expected 15 fields, saw 22\\nSkipping line 520963: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 528810: expected 15 fields, saw 22\\nSkipping line 554419: expected 15 fields, saw 22\\nSkipping line 565266: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 613248: expected 15 fields, saw 22\\nSkipping line 613988: expected 15 fields, saw 22\\nSkipping line 620134: expected 15 fields, saw 22\\nSkipping line 642170: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 670152: expected 15 fields, saw 22\\nSkipping line 681751: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 811638: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 913254: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1168305: expected 15 fields, saw 22\\n'\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/tmp/amazon_reviews_us_Camera_v1_00.tsv.gz', sep='\\t', \n",
    "                   compression='gzip', error_bad_lines=False, dtype='str')\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "studied-tower",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800755, 15)\n",
      "Index(['marketplace', 'customer_id', 'review_id', 'product_id',\n",
      "       'product_parent', 'product_title', 'product_category', 'star_rating',\n",
      "       'helpful_votes', 'total_votes', 'vine', 'verified_purchase',\n",
      "       'review_headline', 'review_body', 'review_date'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-terminology",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "spread-combination",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.iloc[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "herbal-pencil",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['star_rating', 'review_body']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "external-armenia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5', '2', '3', '1', '4'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.star_rating.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "partial-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'] = data.star_rating.map({\n",
    "    '1': '__label__negative__',\n",
    "    '2': '__label__negative__',\n",
    "    '3': '__label__neutral__',\n",
    "    '4': '__label__positive__',\n",
    "    '5': '__label__positive__'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "brown-mailman",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['star_rating'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "capable-slope",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['label', 'review_body']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "streaming-earthquake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__positive__</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__positive__</td>\n",
       "      <td>Perfect, even sturdier than the original!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__negative__</td>\n",
       "      <td>If the words, &amp;#34;Cheap Chinese Junk&amp;#34; com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__positive__</td>\n",
       "      <td>Exactly what I wanted and expected. Perfect fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__positive__</td>\n",
       "      <td>I will look past the fact that they tricked me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 label                                        review_body\n",
       "0  __label__positive__                                                 ok\n",
       "1  __label__positive__          Perfect, even sturdier than the original!\n",
       "2  __label__negative__  If the words, &#34;Cheap Chinese Junk&#34; com...\n",
       "3  __label__positive__  Exactly what I wanted and expected. Perfect fo...\n",
       "4  __label__positive__  I will look past the fact that they tricked me..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "passive-necklace",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "accurate-constant",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-80222ac00e68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review_body'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review_body'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4211\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4212\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4213\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     return [\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     ]\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     return [\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     ]\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/nltk/tokenize/treebank.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, convert_parentheses, return_str)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mregexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubstitution\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPUNCTUATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubstitution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;31m# Handles parentheses.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data['review_body'] = data['review_body'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "jewish-columbia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Perfect,', 'even', 'sturdier', 'than', 'the', 'original!']\n",
      "perfect , even sturdier than the original !\n"
     ]
    }
   ],
   "source": [
    "# we can also tokenize using built python functions and methods.\n",
    "# but it will be time taken, and may cause error\n",
    "sample = \"Perfect, even sturdier than the original!\"\n",
    "sample = sample.split(\" \")\n",
    "print(sample)\n",
    "sample2 = data['review_body'].iloc[1]\n",
    "print(sample2)\n",
    "# it means nltk.tokernizer is better to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "liberal-integer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.6 s, sys: 19.9 ms, total: 1.62 s\n",
      "Wall time: 1.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['review_body'] = data.apply(lambda row: \" \".join(row['review_body']).lower(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "broadband-newton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if the words , & # 34 ; cheap chinese junk & # 34 ; come to your mind when you see this , then congratulate yourself . you 're pretty close . one of the most important features of a 'security camera & # 34 ; is the ability to detect motion and record , especially when running on battery and limited storage space . i tested the motion detect on this camera in a few different environments so far ( i.e . low light , indoors , outdoors , etc.. ) and all i got was a sd card full of video triggers . all the testing was done with the low motion sensitivity setting . i ca n't even imagine what the high one would be. < br / > as others said , the low light operation is poor . i did one of my tests outdoors as the sun was setting . it was good until a point - then the camera started having seizures..it got fuzzy , went to black and white ... back to color ... then ultimately stabilized with lines across the screen. < br / > another oddity i noticed was that the firmware reported in the windows config tool seemed later than the latest version posed on the zetta site . i 'm not exactly sure why that is. < br / > < br / > it gets two stars because there was one time , in a very light controlled indoor environment , where it did n't constantly trigger , so it may have some usefulness for your particular situation . in adequate light , the video is n't too bad ( you do n't need hd for most security applications ) . < br / > < br / > the are a variety of settings that are configurable , which is quite nice . one setting that could , and should , be configurable is the amount of time it will record after the last trigger is detected . the manual states that this is 5 minutes . so , if someone enters the picture for 30 seconds then leaves , you conceivably would have 5 minutes of recording nothing afterwards . this is n't power or memory efficient. < br / > < br / > my original thought was to return this , but i want to crack it open and look at some of the internals . i may decide to make my own. < br / > < br / > i will continue to test and report any new developments .\n"
     ]
    }
   ],
   "source": [
    "sample2 = data['review_body'].iloc[2]\n",
    "print(sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "expired-boards",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training, validation = train_test_split(data, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "burning-removal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95000, 2)\n",
      "(5000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(training.shape)\n",
    "print(validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dried-publication",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('/tmp/training.txt', training.values, fmt='%s')\n",
    "np.savetxt('/tmp/validation.txt', validation.values, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "funded-tucson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__label__positive__ great product for great price . definitely worth the money .\r\n",
      "__label__positive__ very smooth gearing - and mounts nicely on tripod .\r\n"
     ]
    }
   ],
   "source": [
    "!head -2 /tmp/training.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "resistant-bangladesh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.31.1\n"
     ]
    }
   ],
   "source": [
    "# training prepration\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "print(sagemaker.__version__)\n",
    "\n",
    "session = sagemaker.Session()\n",
    "bucket = session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-simple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell if you want to use the data you processed manually\n",
    "\n",
    "prefix = 'amazon-reviews'\n",
    "\n",
    "s3_train_path = session.upload_data(path='/tmp/training.txt', bucket=bucket, key_prefix=prefix+'/input/train')\n",
    "s3_val_path = session.upload_data(path='/tmp/validation.txt', bucket=bucket, key_prefix=prefix+'/input/validation')\n",
    "s3_output = 's3://{}/{}/output/'.format(bucket, prefix)\n",
    "\n",
    "print(s3_train_path)\n",
    "print(s3_val_path)\n",
    "print(s3_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "alpine-importance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811284229777.dkr.ecr.us-east-1.amazonaws.com/blazingtext:1\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import image_uris\n",
    "\n",
    "region = boto3.Session().region_name    \n",
    "container = image_uris.retrieve('blazingtext', region)\n",
    "print(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aerial-polls",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "bt = sagemaker.estimator.Estimator(container,\n",
    "                                   role, \n",
    "                                   instance_count=1, \n",
    "                                   instance_type='ml.c5.2xlarge',\n",
    "                                   output_path=s3_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "absolute-feature",
   "metadata": {},
   "outputs": [],
   "source": [
    "bt.set_hyperparameters(mode='supervised')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "executed-invalid",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.TrainingInput(s3_train_path, \n",
    "                      distribution='FullyReplicated', \n",
    "                      content_type='text/plain',\n",
    "                      s3_data_type='S3Prefix')\n",
    "\n",
    "validation_data = sagemaker.TrainingInput(s3_val_path,\n",
    "                      distribution='FullyReplicated', \n",
    "                      content_type='text/plain', \n",
    "                      s3_data_type='S3Prefix')\n",
    "\n",
    "s3_channels = {'train': train_data, 'validation': validation_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "tropical-legislation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-25 11:33:22 Starting - Starting the training job...\n",
      "2021-04-25 11:33:45 Starting - Launching requested ML instancesProfilerReport-1619350402: InProgress\n",
      "......\n",
      "2021-04-25 11:34:52 Starting - Preparing the instances for training.........\n",
      "2021-04-25 11:36:17 Downloading - Downloading input data\n",
      "2021-04-25 11:36:17 Training - Training image download completed. Training in progress.\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[04/25/2021 11:36:18 WARNING 140665554687616] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[04/25/2021 11:36:18 WARNING 140665554687616] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[04/25/2021 11:36:18 INFO 140665554687616] nvidia-smi took: 0.025143146514892578 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[04/25/2021 11:36:18 INFO 140665554687616] Running single machine CPU BlazingText training using supervised mode.\u001b[0m\n",
      "\u001b[34mNumber of CPU sockets found in instance is  1\u001b[0m\n",
      "\u001b[34m[04/25/2021 11:36:18 INFO 140665554687616] Processing /opt/ml/input/data/train/training.txt . File size: 25.362000465393066 MB\u001b[0m\n",
      "\u001b[34m[04/25/2021 11:36:18 INFO 140665554687616] Processing /opt/ml/input/data/validation/validation.txt . File size: 1.3282623291015625 MB\u001b[0m\n",
      "\u001b[34mRead 5M words\u001b[0m\n",
      "\u001b[34mNumber of words:  15246\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0471  Progress: 5.86%  Million Words/sec: 15.70 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0440  Progress: 11.91%  Million Words/sec: 15.99 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0411  Progress: 17.77%  Million Words/sec: 15.92 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0382  Progress: 23.70%  Million Words/sec: 15.93 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0351  Progress: 29.72%  Million Words/sec: 15.98 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0321  Progress: 35.81%  Million Words/sec: 16.04 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0291  Progress: 41.88%  Million Words/sec: 16.08 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0260  Progress: 47.97%  Million Words/sec: 16.11 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0231  Progress: 53.88%  Million Words/sec: 16.09 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0200  Progress: 59.93%  Million Words/sec: 16.10 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0170  Progress: 66.01%  Million Words/sec: 16.12 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0139  Progress: 72.10%  Million Words/sec: 16.14 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0110  Progress: 77.99%  Million Words/sec: 16.11 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0081  Progress: 83.89%  Million Words/sec: 16.09 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0050  Progress: 89.92%  Million Words/sec: 16.10 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0020  Progress: 95.95%  Million Words/sec: 16.11 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0000  Progress: 100.00%  Million Words/sec: 15.80 #####\u001b[0m\n",
      "\u001b[34mTraining finished.\u001b[0m\n",
      "\u001b[34mAverage throughput in Million words/sec: 15.80\u001b[0m\n",
      "\u001b[34mTotal training time in seconds: 1.71\n",
      "\u001b[0m\n",
      "\u001b[34m#train_accuracy: 0.8994\u001b[0m\n",
      "\u001b[34mNumber of train examples: 95000\n",
      "\u001b[0m\n",
      "\u001b[34m#validation_accuracy: 0.8842\u001b[0m\n",
      "\u001b[34mNumber of validation examples: 5000\u001b[0m\n",
      "\n",
      "2021-04-25 11:36:46 Uploading - Uploading generated training model\n",
      "2021-04-25 11:38:06 Completed - Training job completed\n",
      "Training seconds: 128\n",
      "Billable seconds: 128\n"
     ]
    }
   ],
   "source": [
    "bt.fit(inputs=s3_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "opened-essence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------!"
     ]
    }
   ],
   "source": [
    "bt_predictor = bt.deploy(initial_instance_count=1, instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "union-neighbor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'[{\"label\": [\"__label__negative__\", \"__label__neutral__\", \"__label__positive__\"], \"prob\": [0.9729471802711487, 0.026321984827518463, 0.0007608418236486614]}, {\"label\": [\"__label__neutral__\", \"__label__positive__\", \"__label__negative__\"], \"prob\": [0.555188775062561, 0.30684155225753784, 0.13799965381622314]}, {\"label\": [\"__label__positive__\", \"__label__neutral__\", \"__label__negative__\"], \"prob\": [0.999725878238678, 0.0002516448439564556, 5.2410414355108514e-05]}]'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "#import pprint\n",
    "\n",
    "sentences = ['This is a bad camera it doesnt work at all , i want a refund  .', \n",
    "             'The camera works , the pictures are decent quality, nothing special to say about it .',\n",
    "             'Very happy to have bought this , exactly what I needed']\n",
    "\n",
    "payload = {\"instances\" : sentences, \"configuration\": {\"k\": 3}}\n",
    "\n",
    "bt_predictor.serializer = sagemaker.serializers.JSONSerializer()\n",
    "response = bt_predictor.predict(payload)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "domestic-design",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bytes'>\n"
     ]
    }
   ],
   "source": [
    "# codes not available in the book\n",
    "# parsing the response\n",
    "print(type(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "sophisticated-peripheral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> [{\"label\": [\"__label__negative__\", \"__label__neutral__\", \"__label__positive__\"], \"prob\": [0.9729471802711487, 0.026321984827518463, 0.0007608418236486614]}, {\"label\": [\"__label__neutral__\", \"__label__positive__\", \"__label__negative__\"], \"prob\": [0.555188775062561, 0.30684155225753784, 0.13799965381622314]}, {\"label\": [\"__label__positive__\", \"__label__neutral__\", \"__label__negative__\"], \"prob\": [0.999725878238678, 0.0002516448439564556, 5.2410414355108514e-05]}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = response.decode(\"UTF-8\")\n",
    "print(type(data) ,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dependent-millennium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> [{'label': ['__label__negative__', '__label__neutral__', '__label__positive__'], 'prob': [0.9729471802711487, 0.026321984827518463, 0.0007608418236486614]}, {'label': ['__label__neutral__', '__label__positive__', '__label__negative__'], 'prob': [0.555188775062561, 0.30684155225753784, 0.13799965381622314]}, {'label': ['__label__positive__', '__label__neutral__', '__label__negative__'], 'prob': [0.999725878238678, 0.0002516448439564556, 5.2410414355108514e-05]}]\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "mydata = ast.literal_eval(data) \n",
    "print(type(mydata), mydata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "alone-hospital",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def reviewPrediction(response):\n",
    "    data = response.decode(\"UTF-8\")\n",
    "    myData = ast.literal_eval(data) # oonversting a string (with list and dictionary marker into list or dictionary)\n",
    "    for line in myData:\n",
    "        #print(line, len(line))\n",
    "        label = line['label']\n",
    "        prob = line['prob']\n",
    "        #print(label)\n",
    "        #print(prob)\n",
    "        # np.argmax is not required here, as highest probalities showing at 0 position,\n",
    "        # but for a good practice, we are using np.argmax  \n",
    "        position = np.argmax(prob)\n",
    "        print(label[position])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "suited-juice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__label__negative__\n",
      "__label__neutral__\n",
      "__label__positive__\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "results = reviewPrediction(response)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "changed-seven",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__label__negative__\n",
      "__label__negative__\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "sentences = [' i am  very disappointed . its all rubbish', ' very very bad']\n",
    "\n",
    "payload = {\"instances\" : sentences, \"configuration\": {\"k\": 3}}\n",
    "\n",
    "bt_predictor.serializer = sagemaker.serializers.JSONSerializer()\n",
    "response = bt_predictor.predict(payload)\n",
    "\n",
    "results = reviewPrediction(response)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "guilty-pension",
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-waters",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
